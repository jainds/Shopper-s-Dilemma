{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      "Unnamed: 0                                   1000 non-null int64\n",
      "Retail Purchases – Most Frequent Category    1000 non-null object\n",
      "Gender                                       1000 non-null object\n",
      "Method of Payment                            1000 non-null object\n",
      "Address                                      1000 non-null object\n",
      "Age                                          826 non-null float64\n",
      "Estimated Income                             789 non-null float64\n",
      "Amount Spent on Goods                        826 non-null float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 46.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def func1(data11):\n",
    "    if(np.isnan(data11.Age)):\n",
    "        gender = data11.Gender\n",
    "        purchase = data11.purchase\n",
    "        payment = data11['Method of Payment']\n",
    "        data11.Age = MedianAge[gender][payment][purchase]\n",
    "    return data11\n",
    "\n",
    "def func2(data11):\n",
    "    if(np.isnan(data11['Amount Spent on Goods'])):\n",
    "        gender = data11.Gender\n",
    "        purchase = data11.purchase\n",
    "        payment = data11['Method of Payment']\n",
    "        data11['Amount Spent on Goods'] = MedianAmount[gender][payment][purchase]\n",
    "    return data11\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "data.info()\n",
    "df = data.copy()\n",
    "location_df = df.Address.apply(lambda x: pd.Series(x.split(' ')))\n",
    "location_df['Street Address'] = location_df[1] +' '+ location_df[2]\n",
    "location_df['Ville Address'] = location_df[4] +' '+ location_df[5]\n",
    "location_df['Pin'] = location_df[3]\n",
    "location_df= location_df.drop([0,1,2,3,4,5], axis =1)\n",
    "dataup = df.join(location_df, how='outer')\n",
    "dataup['purchase'] = dataup['Retail Purchases – Most Frequent Category']\n",
    "dataup['Retail Purchases – Most Frequent Category'] = dataup['Retail Purchases \\xe2\\x80\\x93 Most Frequent Category']\n",
    "\n",
    "g1 = dataup.sort_values(by='Age').groupby(['Gender','Method of Payment','purchase'])\n",
    "MedianAge = g1['Age'].median().round()\n",
    "\n",
    "newdata = dataup.copy()\n",
    "newdata['number']=newdata['Unnamed: 0']\n",
    "newdata.drop(['Unnamed: 0','Address'], axis= 1, inplace=True)\n",
    "newdata.fillna(np.NaN, inplace=True)\n",
    "\n",
    "\n",
    "updated = newdata.apply(func1, axis=1)\n",
    "income = updated['Estimated Income']\n",
    "Amount = updated['Amount Spent on Goods']\n",
    "updated.drop(['Estimated Income', 'Amount Spent on Goods'], inplace=True, axis =1)\n",
    "g2 = updated.sort_values(by='Age').groupby(['Gender','Method of Payment','purchase'])\n",
    "MedianAmount = g1['Amount Spent on Goods'].median()\n",
    "updated = newdata.apply(func1, axis=1)\n",
    "\n",
    "amountmissing = updated[updated['Amount Spent on Goods'].isnull()]\n",
    "incomemissing = updated[updated['Estimated Income'].isnull()].copy()\n",
    "\n",
    "updated2 = updated.apply(func2, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator for estimating Income values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a98e964dd5ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mincomemissingcopyvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mincomemissing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Estimated Income'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincomemissingcopyvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mincomemissingcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincomemissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2427\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2428\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2429\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2495\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2496\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   2664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m   2877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2878\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2879\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of '\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2881\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "#clfd.fit(X_train, y_train)\n",
    "\n",
    "#incomemissing = updated[updated['Estimated Income'].isnull()].copy()\n",
    "\n",
    "trainingdata = updated2.copy()\n",
    "\n",
    "le1= LabelEncoder()\n",
    "le1.fit(trainingdata.Gender)\n",
    "le2= LabelEncoder()\n",
    "le2.fit(trainingdata.purchase)\n",
    "le3= LabelEncoder()\n",
    "le3.fit(trainingdata['Method of Payment'])\n",
    "le4= LabelEncoder()\n",
    "le4.fit(trainingdata['Ville Address'])\n",
    "#incomemissing = updated2[updated2['Estimated Income'].isnull()].copy()\n",
    "trainingdata.dropna(inplace=True)\n",
    "incomesmiss = trainingdata['Estimated Income'].copy()\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "trainingdata.drop('Estimated Income', inplace=True, axis =1)\n",
    "trainingdata['Gender'] = trainingdata.Gender.astype('category')\n",
    "trainingdata['Method of Payment'] = trainingdata['Method of Payment'].astype('category')\n",
    "trainingdata['Ville Address'] = trainingdata['Ville Address'].astype('category')\n",
    "trainingdata['purchase'] = trainingdata['purchase'].astype('category')\n",
    "\n",
    "\n",
    "trainingdata1 = trainingdata.copy()\n",
    "trainingdata1.Gender = le1.transform(trainingdata1.Gender)\n",
    "trainingdata1.purchase = le2.transform(trainingdata1.purchase)\n",
    "trainingdata1['Method of Payment'] = le3.transform(trainingdata1['Method of Payment'])\n",
    "trainingdata1['Ville Address'] = le4.transform(trainingdata1['Ville Address'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, incomesmiss, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)\n",
    "incomemissingcopyvalues = clf.predict(trainingdata1)\n",
    "incomemissing['Estimated Income'] = incomemissingcopyvalues\n",
    "incomemissingcopy = incomemissing.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [211, 789]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-89ee8ff13acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mincomemissingcopy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'purchase'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincomemissingcopy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'purchase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrainingdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincomemissingcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomesmiss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [211, 789]"
     ]
    }
   ],
   "source": [
    "incomemissingcopy.drop('number', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Pin', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Street Address', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Estimated Income', inplace=True, axis =1)\n",
    "incomemissingcopy['Gender'] = incomemissingcopy.Gender.astype('category')\n",
    "incomemissingcopy['Method of Payment'] = incomemissingcopy['Method of Payment'].astype('category')\n",
    "incomemissingcopy['Ville Address'] = incomemissingcopy['Ville Address'].astype('category')\n",
    "incomemissingcopy['purchase'] = incomemissingcopy['purchase'].astype('category')\n",
    "trainingdata1 = incomemissingcopy.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, incomesmiss, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "incomemissingcopyvalues = clf.predict(trainingdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 789]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-08a71e9e58f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Method of Payment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Method of Payment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ville Address'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ville Address'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomesmiss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 789]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "incomemissingcopy.drop('number', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Pin', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Street Address', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Estimated Income', inplace=True, axis =1)\n",
    "incomemissingcopy['Gender'] = incomemissingcopy.Gender.astype('category')\n",
    "incomemissingcopy['Method of Payment'] = incomemissingcopy['Method of Payment'].astype('category')\n",
    "incomemissingcopy['Ville Address'] = incomemissingcopy['Ville Address'].astype('category')\n",
    "incomemissingcopy['purchase'] = incomemissingcopy['purchase'].astype('category')\n",
    "trainingdata1 = incomemissingcopy.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, incomesmiss, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "incomemissingcopyvalues = clf.predict(trainingdata1)\n",
    "\n",
    "\n",
    "incomemissing['Estimated Income'] = incomemissingcopyvalues\n",
    "\n",
    "updated3 = updated2.copy()\n",
    "for value in incomemissing.number:\n",
    "    updated3.loc[updated3['number'] == value] = incomemissing.loc[incomemissing['number'] == value]\n",
    "updated3.drop('Retail Purchases – Most Frequent Category', axis =1, inplace=True)\n",
    "\n",
    "\n",
    "clusterdata = updated3.copy()\n",
    "clusterdata.Gender = le1.transform(clusterdata.Gender)\n",
    "clusterdata.purchase = le2.transform(clusterdata.purchase)\n",
    "clusterdata['Method of Payment'] = le3.transform(clusterdata['Method of Payment'])\n",
    "le4.fit(clusterdata['Ville Address'])\n",
    "clusterdata['Ville Address'] = le4.transform(clusterdata['Ville Address'])\n",
    "le5 = LabelEncoder()\n",
    "le5.fit(clusterdata['Street Address'])\n",
    "clusterdata['Street Address'] = le5.transform(clusterdata['Street Address'])\n",
    "import visuals as vs\n",
    "from  sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(clusterdata)\n",
    "\n",
    "\n",
    "pca_samples = pca.transform(clusterdata)\n",
    "\n",
    "\n",
    "pca_results = vs.pca_results(clusterdata, pca)\n",
    "\n",
    "pca = PCA(n_components=2).fit(clusterdata)\n",
    "\n",
    "\n",
    "reduced_data = pca.transform(clusterdata)\n",
    "\n",
    "\n",
    "reduced_data = pd.DataFrame(reduced_data, columns = ['Dimension 1', 'Dimension 2'])\n",
    "\n",
    "clusterer = KMeans(n_clusters=2, random_state=29).fit(reduced_data)\n",
    "\n",
    "preds = clusterer.predict(reduced_data)\n",
    "centers = clusterer.cluster_centers_\n",
    "\n",
    "\n",
    "score = silhouette_score(reduced_data, clusterer.labels_, metric='euclidean')\n",
    "print(\"KMeans score\", score)\n",
    "true_centers = pca.inverse_transform(centers)\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "segments = ['Segment {}'.format(i) for i in range(0,len(centers))]\n",
    "true_centers = pd.DataFrame(np.round(true_centers), columns = clusterdata.keys())\n",
    "true_centers.index = segments\n",
    "\n",
    "print \"Actual cluster centers\"\n",
    "display(true_centers)\n",
    "\n",
    "org_data=pca.inverse_transform(reduced_data)\n",
    "org_ata = pd.DataFrame(np.round(org_data), columns = clusterdata.keys())\n",
    "\n",
    "clusterer = KMeans(n_clusters=2, random_state=29).fit(clusterdata)\n",
    "\n",
    "preds = clusterer.predict(clusterdata)\n",
    "centers = clusterer.cluster_centers_\n",
    "score = silhouette_score(clusterdata, clusterer.labels_, metric='euclidean')\n",
    "print(\"KMeans score\", score)\n",
    "\n",
    "segments = ['Segment {}'.format(i) for i in range(0,len(centers))]\n",
    "true_centers = pd.DataFrame(np.round(true_centers), columns = clusterdata.keys())\n",
    "true_centers.index = segments\n",
    "display(true_centers)\n",
    "\n",
    "clusterdata.purchase = le2.inverse_transform(clusterdata.purchase)\n",
    "\n",
    "clusterdata['Method of Payment'] = le3.inverse_transform(clusterdata['Method of Payment'])\n",
    "clusterdata['Ville Address'] = le4.inverse_transform(clusterdata['Ville Address'])\n",
    "clusterdata['Street Address'] = le5.inverse_transform(clusterdata['Street Address'])\n",
    "\n",
    "\n",
    "group1 = pd.DataFrame(columns=org_ata.columns)\n",
    "group2 = pd.DataFrame(columns=org_ata.columns)\n",
    "for i in range(0,1000):\n",
    "    if(preds[i]):\n",
    "        group1 = group1.append(clusterdata.loc[i])\n",
    "    else:\n",
    "        group2 = group2.append(clusterdata.loc[i])\n",
    "        \n",
    "productlist1 = group1.copy()\n",
    "productlist2 = group2.copy()\n",
    "productlist1.drop(['Street Address', 'Pin', 'number', 'Estimated Income'], axis =1, inplace=True)\n",
    "productlist2.drop(['Street Address', 'Pin', 'number', 'Estimated Income'], axis =1, inplace=True)\n",
    "\n",
    "productlist1.Gender = le1.transform(productlist1.Gender)\n",
    "productlist1.purchase = le2.transform(productlist1.purchase)\n",
    "\n",
    "productlist1['Method of Payment'] = le3.transform(productlist1['Method of Payment'])\n",
    "productlist1['Ville Address'] = le4.transform(productlist1['Ville Address'])\n",
    "\n",
    "cs= cosine_similarity(productlist1)\n",
    "\n",
    "pds = pd.DataFrame(cs)\n",
    "pds.iloc[1].nlargest(n=3, keep = 'first').index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      LabelEncoder()\n",
       "2      LabelEncoder()\n",
       "3      LabelEncoder()\n",
       "5      LabelEncoder()\n",
       "6      LabelEncoder()\n",
       "7      LabelEncoder()\n",
       "8      LabelEncoder()\n",
       "10     LabelEncoder()\n",
       "11     LabelEncoder()\n",
       "12     LabelEncoder()\n",
       "14     LabelEncoder()\n",
       "15     LabelEncoder()\n",
       "16     LabelEncoder()\n",
       "17     LabelEncoder()\n",
       "18     LabelEncoder()\n",
       "19     LabelEncoder()\n",
       "21     LabelEncoder()\n",
       "22     LabelEncoder()\n",
       "23     LabelEncoder()\n",
       "24     LabelEncoder()\n",
       "25     LabelEncoder()\n",
       "26     LabelEncoder()\n",
       "27     LabelEncoder()\n",
       "28     LabelEncoder()\n",
       "30     LabelEncoder()\n",
       "31     LabelEncoder()\n",
       "33     LabelEncoder()\n",
       "34     LabelEncoder()\n",
       "35     LabelEncoder()\n",
       "36     LabelEncoder()\n",
       "            ...      \n",
       "962    LabelEncoder()\n",
       "963    LabelEncoder()\n",
       "966    LabelEncoder()\n",
       "967    LabelEncoder()\n",
       "968    LabelEncoder()\n",
       "969    LabelEncoder()\n",
       "970    LabelEncoder()\n",
       "971    LabelEncoder()\n",
       "972    LabelEncoder()\n",
       "974    LabelEncoder()\n",
       "976    LabelEncoder()\n",
       "977    LabelEncoder()\n",
       "979    LabelEncoder()\n",
       "980    LabelEncoder()\n",
       "983    LabelEncoder()\n",
       "984    LabelEncoder()\n",
       "985    LabelEncoder()\n",
       "986    LabelEncoder()\n",
       "987    LabelEncoder()\n",
       "988    LabelEncoder()\n",
       "989    LabelEncoder()\n",
       "990    LabelEncoder()\n",
       "992    LabelEncoder()\n",
       "993    LabelEncoder()\n",
       "994    LabelEncoder()\n",
       "995    LabelEncoder()\n",
       "996    LabelEncoder()\n",
       "997    LabelEncoder()\n",
       "998    LabelEncoder()\n",
       "999    LabelEncoder()\n",
       "Name: Gender, Length: 789, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata1.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.transform(['Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainingdata = updated.copy()\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Amount Spent on Goods', inplace=True, axis =1)\n",
    "trainingdata.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "trainingdata.drop('Estimated Income', inplace=True, axis =1)\n",
    "amountava = updated['Amount Spent on Goods']\n",
    "trainingdata['Gender'] = trainingdata.Gender.astype('category')\n",
    "trainingdata['Method of Payment'] = trainingdata['Method of Payment'].astype('category')\n",
    "trainingdata['Ville Address'] = trainingdata['Ville Address'].astype('category')\n",
    "trainingdata['purchase'] = trainingdata['purchase'].astype('category')\n",
    "\n",
    "\n",
    "le1= LabelEncoder()\n",
    "le1.fit(trainingdata.Gender)\n",
    "le2= LabelEncoder()\n",
    "le2.fit(trainingdata.purchase)\n",
    "le3= LabelEncoder()\n",
    "le3.fit(trainingdata['Method of Payment'])\n",
    "le4= LabelEncoder()\n",
    "le4.fit(trainingdata['Ville Address'])\n",
    "trainingdata1 = trainingdata.copy()\n",
    "trainingdata1.Gender = le1.transform(trainingdata1.Gender)\n",
    "trainingdata1.purchase = le2.transform(trainingdata1.purchase)\n",
    "trainingdata1['Method of Payment'] = le3.transform(trainingdata1['Method of Payment'])\n",
    "trainingdata1['Ville Address'] = le4.transform(trainingdata1['Ville Address'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, amountava, test_size=0.33, random_state=42)\n",
    "\n",
    "#clf = LinearRegression()\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "#clfd = DecisionTreeRegressor()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clfd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainingdata = updated2.copy()\n",
    "incomemissing = updated2[updated2['Estimated Income'].isnull()].copy()\n",
    "trainingdata.dropna(inplace=True)\n",
    "incomesmiss = trainingdata['Estimated Income'].copy()\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "trainingdata.drop('Estimated Income', inplace=True, axis =1)\n",
    "trainingdata['Gender'] = trainingdata.Gender.astype('category')\n",
    "trainingdata['Method of Payment'] = trainingdata['Method of Payment'].astype('category')\n",
    "trainingdata['Ville Address'] = trainingdata['Ville Address'].astype('category')\n",
    "trainingdata['purchase'] = trainingdata['purchase'].astype('category')\n",
    "le9= LabelEncoder()\n",
    "le9.fit(trainingdata.Gender)\n",
    "le2= LabelEncoder()\n",
    "le2.fit(trainingdata.purchase)\n",
    "le3= LabelEncoder()\n",
    "le3.fit(trainingdata['Method of Payment'])\n",
    "le4= LabelEncoder()\n",
    "le4.fit(trainingdata['Ville Address'])\n",
    "trainingdata1 = trainingdata.copy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
