{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final worksheet to read data from csv, fill missing data, estimate income, cluster the users, find similarities between products, recommend products based on similarity and cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the required libraries, create required functions: func1 and func2, read data from csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      "Unnamed: 0                                   1000 non-null int64\n",
      "Retail Purchases – Most Frequent Category    1000 non-null object\n",
      "Gender                                       1000 non-null object\n",
      "Method of Payment                            1000 non-null object\n",
      "Address                                      1000 non-null object\n",
      "Age                                          826 non-null float64\n",
      "Estimated Income                             789 non-null float64\n",
      "Amount Spent on Goods                        826 non-null float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display\n",
    "\n",
    "def func1(data11):\n",
    "    if(np.isnan(data11.Age)):\n",
    "        gender = data11.Gender\n",
    "        purchase = data11.purchase\n",
    "        payment = data11['Method of Payment']\n",
    "        data11.Age = MedianAge[gender][payment][purchase]\n",
    "    return data11\n",
    "\n",
    "def func2(data11):\n",
    "    if(np.isnan(data11['Amount Spent on Goods'])):\n",
    "        gender = data11.Gender\n",
    "        purchase = data11.purchase\n",
    "        payment = data11['Method of Payment']\n",
    "        data11['Amount Spent on Goods'] = MedianAmount[gender][payment][purchase]\n",
    "    return data11\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "data.info()\n",
    "df = data.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting location information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_df = df.Address.apply(lambda x: pd.Series(x.split(' ')))\n",
    "location_df['Street Address'] = location_df[1] +' '+ location_df[2]\n",
    "location_df['Ville Address'] = location_df[4] +' '+ location_df[5]\n",
    "location_df['Pin'] = location_df[3]\n",
    "location_df= location_df.drop([0,1,2,3,4,5], axis =1)\n",
    "dataup = df.join(location_df, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied few column manipulations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataup['purchase'] = dataup['Retail Purchases – Most Frequent Category']\n",
    "dataup['Retail Purchases – Most Frequent Category'] = dataup['Retail Purchases \\xe2\\x80\\x93 Most Frequent Category']\n",
    "dataup.drop(['Retail Purchases – Most Frequent Category'], axis =1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill missing values in Age and Amount spent on goods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = dataup.sort_values(by='Age').groupby(['Gender','Method of Payment','purchase'])\n",
    "MedianAge = g1['Age'].median().round()\n",
    "\n",
    "newdata = dataup.copy()\n",
    "newdata['number']=newdata['Unnamed: 0']\n",
    "newdata.drop(['Unnamed: 0','Address'], axis= 1, inplace=True)\n",
    "newdata.fillna(np.NaN, inplace=True)\n",
    "\n",
    "\n",
    "updated = newdata.apply(func1, axis=1)\n",
    "income = updated['Estimated Income']\n",
    "Amount = updated['Amount Spent on Goods']\n",
    "updated.drop(['Estimated Income', 'Amount Spent on Goods'], inplace=True, axis =1)\n",
    "g2 = updated.sort_values(by='Age').groupby(['Gender','Method of Payment','purchase'])\n",
    "MedianAmount = g1['Amount Spent on Goods'].median()\n",
    "updated = newdata.apply(func1, axis=1)\n",
    "\n",
    "amountmissing = updated[updated['Amount Spent on Goods'].isnull()]\n",
    "incomemissing = updated[updated['Estimated Income'].isnull()].copy()\n",
    "\n",
    "updated2 = updated.apply(func2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating the income and storing the updated value in *updated3* variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.520494430376\n"
     ]
    }
   ],
   "source": [
    "trainingdata = updated2.copy()\n",
    "trainingdata.dropna(inplace=True)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "incomesmiss = trainingdata['Estimated Income'].copy()\n",
    "trainingdata1 = trainingdata.copy()\n",
    "trainingdata1.drop(['Estimated Income'], axis =1, inplace=True)\n",
    "incomemissing = updated2[updated2['Estimated Income'].isnull()].copy()\n",
    "incomemissingcopy = incomemissing.copy()\n",
    "incomemissingcopy.drop('number', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Pin', inplace=True, axis =1)\n",
    "incomemissingcopy.drop('Street Address', inplace=True, axis =1)\n",
    "\n",
    "incomemissingcopy.drop('Estimated Income', inplace=True, axis =1)\n",
    "incomemissingcopy['Gender'] = incomemissingcopy.Gender.astype('category')\n",
    "incomemissingcopy['Method of Payment'] = incomemissingcopy['Method of Payment'].astype('category')\n",
    "incomemissingcopy['Ville Address'] = incomemissingcopy['Ville Address'].astype('category')\n",
    "incomemissingcopy['purchase'] = incomemissingcopy['purchase'].astype('category')\n",
    "\n",
    "trainingdata1.Gender = le1.transform(trainingdata1.Gender)\n",
    "trainingdata1.purchase = le2.transform(trainingdata1.purchase)\n",
    "trainingdata1['Method of Payment'] = le3.transform(trainingdata1['Method of Payment'])\n",
    "trainingdata1['Ville Address'] = le4.transform(trainingdata1['Ville Address'])\n",
    "\n",
    "incomemissingcopy.Gender = le1.transform(incomemissingcopy.Gender)\n",
    "incomemissingcopy.purchase = le2.transform(incomemissingcopy.purchase)\n",
    "incomemissingcopy['Method of Payment'] = le3.transform(incomemissingcopy['Method of Payment'])\n",
    "incomemissingcopy['Ville Address'] = le4.transform(incomemissingcopy['Ville Address'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, incomesmiss, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "\n",
    "incomemissingcopyvalues = clf.predict(incomemissingcopy)\n",
    "\n",
    "\n",
    "incomemissing['Estimated Income'] = incomemissingcopyvalues\n",
    "\n",
    "updated3 = updated2.copy()\n",
    "for value in incomemissing.number:\n",
    "    updated3.loc[updated3['number'] == value] = incomemissing.loc[incomemissing['number'] == value]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KMeans score', 0.50874056595535633)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Method of Payment</th>\n",
       "      <th>Age</th>\n",
       "      <th>Estimated Income</th>\n",
       "      <th>Amount Spent on Goods</th>\n",
       "      <th>Street Address</th>\n",
       "      <th>Ville Address</th>\n",
       "      <th>Pin</th>\n",
       "      <th>purchase</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Segment 0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32944.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>75431.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Segment 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34868.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>25958.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender  Method of Payment   Age  Estimated Income  \\\n",
       "Segment 0     1.0                0.0  37.0           32944.0   \n",
       "Segment 1     0.0                0.0  38.0           34868.0   \n",
       "\n",
       "           Amount Spent on Goods  Street Address  Ville Address      Pin  \\\n",
       "Segment 0                   22.0           266.0          180.0  75431.0   \n",
       "Segment 1                   24.0           253.0          187.0  25958.0   \n",
       "\n",
       "           purchase  number  \n",
       "Segment 0       3.0   497.0  \n",
       "Segment 1       3.0   502.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusterdata = updated3.copy()\n",
    "clusterdata.Gender = le1.transform(clusterdata.Gender)\n",
    "clusterdata.purchase = le2.transform(clusterdata.purchase)\n",
    "clusterdata['Method of Payment'] = le3.transform(clusterdata['Method of Payment'])\n",
    "le4.fit(clusterdata['Ville Address'])\n",
    "clusterdata['Ville Address'] = le4.transform(clusterdata['Ville Address'])\n",
    "le5 = LabelEncoder()\n",
    "le5.fit(clusterdata['Street Address'])\n",
    "clusterdata['Street Address'] = le5.transform(clusterdata['Street Address'])\n",
    "\n",
    "clusterer = KMeans(n_clusters=2, random_state=29).fit(clusterdata)\n",
    "\n",
    "preds = clusterer.predict(clusterdata)\n",
    "centers = clusterer.cluster_centers_\n",
    "score = silhouette_score(clusterdata, clusterer.labels_, metric='euclidean')\n",
    "print(\"KMeans score\", score)\n",
    "\n",
    "segments = ['Segment {}'.format(i) for i in range(0,len(centers))]\n",
    "true_centers = pd.DataFrame(np.round(centers), columns = clusterdata.keys())\n",
    "true_centers.index = segments\n",
    "display(true_centers)\n",
    "\n",
    "clusterdata.purchase = le2.inverse_transform(clusterdata.purchase)\n",
    "\n",
    "clusterdata['Method of Payment'] = le3.inverse_transform(clusterdata['Method of Payment'])\n",
    "clusterdata['Ville Address'] = le4.inverse_transform(clusterdata['Ville Address'])\n",
    "clusterdata['Street Address'] = le5.inverse_transform(clusterdata['Street Address'])\n",
    "\n",
    "\n",
    "group1 = pd.DataFrame(columns=clusterdata.columns)\n",
    "group2 = pd.DataFrame(columns=clusterdata.columns)\n",
    "for i in range(0,1000):\n",
    "    if(preds[i]):\n",
    "        group1 = group1.append(clusterdata.loc[i])\n",
    "    else:\n",
    "        group2 = group2.append(clusterdata.loc[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "productlist1 = group1.copy()\n",
    "productlist2 = group2.copy()\n",
    "productlist1.drop(['Street Address', 'Pin', 'number', 'Estimated Income'], axis =1, inplace=True)\n",
    "productlist2.drop(['Street Address', 'Pin', 'number', 'Estimated Income'], axis =1, inplace=True)\n",
    "\n",
    "\n",
    "productlist1.purchase = le2.transform(productlist1.purchase)\n",
    "\n",
    "productlist1['Method of Payment'] = le3.transform(productlist1['Method of Payment'])\n",
    "productlist1['Ville Address'] = le4.transform(productlist1['Ville Address'])\n",
    "\n",
    "cs= cosine_similarity(productlist1)\n",
    "\n",
    "pds = pd.DataFrame(cs)\n",
    "pds.iloc[1].nlargest(n=3, keep = 'first').index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      "Gender                   1000 non-null object\n",
      "Method of Payment        1000 non-null object\n",
      "Age                      1000 non-null float64\n",
      "Estimated Income         789 non-null float64\n",
      "Amount Spent on Goods    826 non-null float64\n",
      "Street Address           1000 non-null object\n",
      "Ville Address            1000 non-null object\n",
      "Pin                      1000 non-null object\n",
      "purchase                 1000 non-null object\n",
      "number                   1000 non-null int64\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "updated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-514c9074ef07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mincomemissingcopyvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mincomemissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Estimated Income'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincomemissingcopyvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mincomemissingcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincomemissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/anaconda2_410/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/anaconda2_410/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2485\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2486\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/anaconda2_410/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nbuser/anaconda2_410/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, incomesmiss, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)\n",
    "incomemissingcopyvalues = clf.predict(trainingdata1)\n",
    "incomemissing['Estimated Income'] = incomemissingcopyvalues\n",
    "incomemissingcopy = incomemissing.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomemissingcopyvalues.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 789]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-08a71e9e58f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Method of Payment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Method of Payment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ville Address'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ville Address'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomesmiss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 789]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      LabelEncoder()\n",
       "2      LabelEncoder()\n",
       "3      LabelEncoder()\n",
       "5      LabelEncoder()\n",
       "6      LabelEncoder()\n",
       "7      LabelEncoder()\n",
       "8      LabelEncoder()\n",
       "10     LabelEncoder()\n",
       "11     LabelEncoder()\n",
       "12     LabelEncoder()\n",
       "14     LabelEncoder()\n",
       "15     LabelEncoder()\n",
       "16     LabelEncoder()\n",
       "17     LabelEncoder()\n",
       "18     LabelEncoder()\n",
       "19     LabelEncoder()\n",
       "21     LabelEncoder()\n",
       "22     LabelEncoder()\n",
       "23     LabelEncoder()\n",
       "24     LabelEncoder()\n",
       "25     LabelEncoder()\n",
       "26     LabelEncoder()\n",
       "27     LabelEncoder()\n",
       "28     LabelEncoder()\n",
       "30     LabelEncoder()\n",
       "31     LabelEncoder()\n",
       "33     LabelEncoder()\n",
       "34     LabelEncoder()\n",
       "35     LabelEncoder()\n",
       "36     LabelEncoder()\n",
       "            ...      \n",
       "962    LabelEncoder()\n",
       "963    LabelEncoder()\n",
       "966    LabelEncoder()\n",
       "967    LabelEncoder()\n",
       "968    LabelEncoder()\n",
       "969    LabelEncoder()\n",
       "970    LabelEncoder()\n",
       "971    LabelEncoder()\n",
       "972    LabelEncoder()\n",
       "974    LabelEncoder()\n",
       "976    LabelEncoder()\n",
       "977    LabelEncoder()\n",
       "979    LabelEncoder()\n",
       "980    LabelEncoder()\n",
       "983    LabelEncoder()\n",
       "984    LabelEncoder()\n",
       "985    LabelEncoder()\n",
       "986    LabelEncoder()\n",
       "987    LabelEncoder()\n",
       "988    LabelEncoder()\n",
       "989    LabelEncoder()\n",
       "990    LabelEncoder()\n",
       "992    LabelEncoder()\n",
       "993    LabelEncoder()\n",
       "994    LabelEncoder()\n",
       "995    LabelEncoder()\n",
       "996    LabelEncoder()\n",
       "997    LabelEncoder()\n",
       "998    LabelEncoder()\n",
       "999    LabelEncoder()\n",
       "Name: Gender, Length: 789, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdata1.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.transform(['Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainingdata = updated.copy()\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Amount Spent on Goods', inplace=True, axis =1)\n",
    "trainingdata.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "trainingdata.drop('Estimated Income', inplace=True, axis =1)\n",
    "amountava = updated['Amount Spent on Goods']\n",
    "trainingdata['Gender'] = trainingdata.Gender.astype('category')\n",
    "trainingdata['Method of Payment'] = trainingdata['Method of Payment'].astype('category')\n",
    "trainingdata['Ville Address'] = trainingdata['Ville Address'].astype('category')\n",
    "trainingdata['purchase'] = trainingdata['purchase'].astype('category')\n",
    "\n",
    "\n",
    "le1= LabelEncoder()\n",
    "le1.fit(trainingdata.Gender)\n",
    "le2= LabelEncoder()\n",
    "le2.fit(trainingdata.purchase)\n",
    "le3= LabelEncoder()\n",
    "le3.fit(trainingdata['Method of Payment'])\n",
    "le4= LabelEncoder()\n",
    "le4.fit(trainingdata['Ville Address'])\n",
    "trainingdata1 = trainingdata.copy()\n",
    "trainingdata1.Gender = le1.transform(trainingdata1.Gender)\n",
    "trainingdata1.purchase = le2.transform(trainingdata1.purchase)\n",
    "trainingdata1['Method of Payment'] = le3.transform(trainingdata1['Method of Payment'])\n",
    "trainingdata1['Ville Address'] = le4.transform(trainingdata1['Ville Address'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingdata1, amountava, test_size=0.33, random_state=42)\n",
    "\n",
    "#clf = LinearRegression()\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "#clfd = DecisionTreeRegressor()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clfd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainingdata = updated2.copy()\n",
    "incomemissing = updated2[updated2['Estimated Income'].isnull()].copy()\n",
    "trainingdata.dropna(inplace=True)\n",
    "incomesmiss = trainingdata['Estimated Income'].copy()\n",
    "trainingdata.drop('number', inplace=True, axis =1)\n",
    "trainingdata.drop('Pin', inplace=True, axis =1)\n",
    "trainingdata.drop('Street Address', inplace=True, axis =1)\n",
    "trainingdata.drop('Retail Purchases – Most Frequent Category', inplace=True, axis =1)\n",
    "trainingdata.drop('Estimated Income', inplace=True, axis =1)\n",
    "trainingdata['Gender'] = trainingdata.Gender.astype('category')\n",
    "trainingdata['Method of Payment'] = trainingdata['Method of Payment'].astype('category')\n",
    "trainingdata['Ville Address'] = trainingdata['Ville Address'].astype('category')\n",
    "trainingdata['purchase'] = trainingdata['purchase'].astype('category')\n",
    "le9= LabelEncoder()\n",
    "le9.fit(trainingdata.Gender)\n",
    "le2= LabelEncoder()\n",
    "le2.fit(trainingdata.purchase)\n",
    "le3= LabelEncoder()\n",
    "le3.fit(trainingdata['Method of Payment'])\n",
    "le4= LabelEncoder()\n",
    "le4.fit(trainingdata['Ville Address'])\n",
    "trainingdata1 = trainingdata.copy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
